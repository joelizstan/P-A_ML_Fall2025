{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe757389",
   "metadata": {},
   "source": [
    "# Ready for your first Kaggle competition?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1ad510",
   "metadata": {},
   "source": [
    "Kaggle is a popular platform that hosts machine learning competitions.\n",
    "\n",
    "The platform helps users to interact via forums and shared code, fostering both collaboration and competition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c2d535",
   "metadata": {},
   "source": [
    "1. Go to the Kaggle competition [website](https://www.kaggle.com/competitions).\n",
    "2. Register for an account (it's free).\n",
    "3. Find the __House Prices - Advanced Regression Techniques__\n",
    "4. Go to the Data tab, read the description, download the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cd52f3",
   "metadata": {},
   "source": [
    "## Inspect the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e46675",
   "metadata": {},
   "source": [
    "Use pandas python package read the csv files and inspect the data: \n",
    "* How many examples? \n",
    "* How many features?\n",
    "* Are there non-numerial values? If so how do you handle these cases?\n",
    "* Are there NaNs? and if so how do you handle such cases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b6c2ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4aa3ad04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 1460 examples and 81 features.\n",
      "The dataset contains 43 non-numerical features:\n",
      "['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition']\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../data/house-prices-advanced-regression-techniques/train.csv')\n",
    "# Display how many examples and features are in the dataset\n",
    "print(f\"The dataset contains {df.shape[0]} examples and {df.shape[1]} features.\")\n",
    "# Non-numerical values in the dataset\n",
    "non_numerical = df.select_dtypes(exclude=['number'])\n",
    "print(f\"The dataset contains {non_numerical.shape[1]} non-numerical features:\")\n",
    "print(non_numerical.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba8b3d7",
   "metadata": {},
   "source": [
    "## Class to load the Training, Validation and Test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89e23119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from d2l import torch as d2l\n",
    "\n",
    "class KaggleHouse(d2l.DataModule):\n",
    "    def __init__(self, batch_size, train=None, val=None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        if self.train is None:\n",
    "            # read the csv files:\n",
    "            self.raw_train = pd.read_csv('../data/house-prices-advanced-regression-techniques/train.csv')\n",
    "            self.raw_test = pd.read_csv('../data/house-prices-advanced-regression-techniques/test.csv')\n",
    "\n",
    "    def preprocess(self, train_frac=0.8):\n",
    "        \"\"\"All the things you noticed about the data that needs preprocessing \n",
    "           can be addressed here.\n",
    "        \"\"\"\n",
    "        label_col_name = \"SalePrice\"\n",
    "        features_train = self.raw_train.drop(columns=['Id', label_col_name])\n",
    "        features_test = self.raw_test.drop(columns=['Id'])\n",
    "\n",
    "        # Handle NaN in numerical variables\n",
    "        all_features = pd.concat([features_train, features_test], ignore_index=True)\n",
    "        numeric_features = all_features.select_dtypes(include=['number'])\n",
    "        numeric_features = numeric_features.fillna(numeric_features.mean())\n",
    "        # Standardize numerical variables\n",
    "        numeric_features = (numeric_features - numeric_features.mean()) / numeric_features.std()\n",
    "        all_features.update(numeric_features)\n",
    "        # Handle categorical features\n",
    "        all_features = pd.get_dummies(all_features, dummy_na=True)\n",
    "        # Inspect the dataset at every step\n",
    "        n_train = features_train.shape[0]\n",
    "        final_train = all_features[:n_train]\n",
    "        final_test = all_features[n_train:]\n",
    "        \n",
    "        self.train = final_train\n",
    "        self.val = final_train.sample(frac=1 - train_frac, random_state=42)\n",
    "        self.test = final_test\n",
    "        print('Train shape:', self.train.shape)\n",
    "        print('Val shape:', self.val.shape)\n",
    "        print('Test shape:', self.test.shape)\n",
    "\n",
    "        # Sanity check: train and test must have the same number of features.\n",
    "\n",
    "    def get_dataloader(self, train):\n",
    "        \"\"\"Define the data tensor (features tensor, labels tensor reshaped appropriately (i.e. (-1, 1))).\n",
    "           Note: all the examples need ot be tensors so you need to pass the numpy arrays to torch.tensor.\n",
    "           Note: Better taking the Logarithm of prices.\"\"\"\n",
    "        \n",
    "        label = \"SalePrice\"\n",
    "        data = self.train if train else self.val\n",
    "\n",
    "        if data is None or label not in data:\n",
    "            raise ValueError(f\"The required label column '{label}' is missing in the data.\")\n",
    "        \n",
    "        if label not in data: \n",
    "            return\n",
    "        else:\n",
    "            features = torch.tensor(data.drop(columns=[label]).values, dtype=torch.float32)\n",
    "            labels = torch.tensor(data[label].values, dtype=torch.float32).reshape(-1, 1)\n",
    "            tensors = (features, labels)\n",
    "            \n",
    "        return self.get_tensorloader(tensors, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8951e8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = KaggleHouse(batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd9d4a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1460, 330)\n",
      "Val shape: (292, 330)\n",
      "Test shape: (1459, 330)\n"
     ]
    }
   ],
   "source": [
    "# Insert some prints in the preprocess function so that you can verify everything is as expected\n",
    "data.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "38786ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1460, 330)\n",
      "Val shape: (292, 330)\n",
      "Test shape: (1459, 330)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The required label column 'SalePrice' is missing in the data.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m data\u001b[38;5;241m.\u001b[39mpreprocess()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Test the data loader: check features and labels dimensions.\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[36], line 53\u001b[0m, in \u001b[0;36mKaggleHouse.get_dataloader\u001b[0;34m(self, train)\u001b[0m\n\u001b[1;32m     50\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain \u001b[38;5;28;01mif\u001b[39;00m train \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m label \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe required label column \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is missing in the data.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m data: \n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: The required label column 'SalePrice' is missing in the data."
     ]
    }
   ],
   "source": [
    "# Ensure the data is preprocessed before testing the data loader\n",
    "data.preprocess()\n",
    "\n",
    "# Test the data loader: check features and labels dimensions.\n",
    "data.get_dataloader(train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5297c560",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b94fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you could define your own regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfefbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is complete: if you have done everything correctly this should work without modify anything\n",
    "def your_training(trainer, data, lr=0.01):\n",
    "    # Get the training dataloader\n",
    "    train_loader = data.get_dataloader(train=True)\n",
    "\n",
    "    model = d2l.LinearRegression(lr) # Initialize the model\n",
    "    model.board.yscale='log'         # iterative loss plot\n",
    "\n",
    "    trainer.fit(model, data)         # fit model to data\n",
    "\n",
    "    return model                     # return the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9ba5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jordanstanley/miniconda3/envs/d2l/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# define the trainer (we can use the built in d2l.Trainer)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m d2l\u001b[38;5;241m.\u001b[39mTrainer(max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m your_model \u001b[38;5;241m=\u001b[39m \u001b[43myour_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[29], line 9\u001b[0m, in \u001b[0;36myour_training\u001b[0;34m(trainer, data, lr)\u001b[0m\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m d2l\u001b[38;5;241m.\u001b[39mLinearRegression(lr) \u001b[38;5;66;03m# Initialize the model\u001b[39;00m\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mboard\u001b[38;5;241m.\u001b[39myscale\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog\u001b[39m\u001b[38;5;124m'\u001b[39m         \u001b[38;5;66;03m# iterative loss plot\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m         \u001b[38;5;66;03m# fit model to data\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.9/site-packages/d2l/torch.py:278\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, data)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, data):\n\u001b[0;32m--> 278\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_model(model)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfigure_optimizers()\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.9/site-packages/d2l/torch.py:268\u001b[0m, in \u001b[0;36mTrainer.prepare_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataloader \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mtrain_dataloader()\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_dataloader \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mval_dataloader()\n\u001b[0;32m--> 268\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_train_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_val_batches \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_dataloader)\n\u001b[1;32m    270\u001b[0m                         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_dataloader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "# define the trainer (we can use the built in d2l.Trainer)\n",
    "trainer = d2l.Trainer(max_epochs=20)\n",
    "your_model = your_training(trainer, data, lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2332d1",
   "metadata": {},
   "source": [
    "## Evaluate your model on the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a85aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = # remember that \"data\" contains also the preprocessed testset\n",
    "your_predictions = your_model(torch.tensor(testset, dtype=torch.float32))\n",
    "# NOTE: we trained the model to predict  the log of the labels.\n",
    "preds_exp = 10**your_predictions.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a071aa6",
   "metadata": {},
   "source": [
    "## Now save your predictions in a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c576acc",
   "metadata": {},
   "source": [
    "Read carefully the format they want the predction to be and create the csv file accordingly.\n",
    "\n",
    "They want two columns, comma separated values, 'Id' and 'SalePrice'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed869df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = # Create the predictions dataset\n",
    "\n",
    "submission.to_csv('./solutions/my_submission_solution.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd477e73",
   "metadata": {},
   "source": [
    "## Submit your predition to the Kaggle competition and see your score!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26cf5e1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
